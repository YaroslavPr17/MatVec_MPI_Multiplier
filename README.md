# Лабораторная работа #2. Линейная алгебра
**Реализация алгоритма умножения матрицы на вектор с помощью библиотеки MPI (Message Passing Interface)**

## Постановка задачи
Задача: _имплементировать 3 алгоритма умножения матрицы на вектор_:
1. При разбиении по строкам
    <p align="center">
        <img src="https://github.com/YaroslavPr17/MatVec_MPI_Multiplier/assets/77925460/0b3ac7fd-de71-4d5e-b023-5f14b12721df" alt="image" width="50%" height="auto">
    </p>

2. При разбиении по столбцам
    <p align="center">
        <img src="https://github.com/YaroslavPr17/MatVec_MPI_Multiplier/assets/77925460/f35792fb-4dff-4c9b-9819-a40afab27364" alt="image" width="70%" height="auto">
    </p>

3. При блочном разбиении
    <p align="center">
        <img src="https://github.com/YaroslavPr17/MatVec_MPI_Multiplier/assets/77925460/cc371ccf-88b3-4ea3-948f-aa2f1fdc1bed" alt="image" width="40%" height="auto">
    </p>


## Описание исходных данных
### Количество исполняющих процессов
* **Количество исполняющих процессов** менее или кратно количеству физических ядер CPU.
### Тип данных
* `double`
### Матрица
* **Размер матрицы** для консистентности экспериментов в каждой размерности кратен каждому значению количества исполняющих процессов
### Вектор
* **Размер вектора** равен второй размерности матрицы (количество столбцов матрицы). То есть, если размер матрицы равен $(24 * 48)$, то длина вектора будет равна $48$.

> Генерация данных выполнялась средствами Python-библиотеки `numpy` с последующим сохранением в текстовый файл значений `double` в формате `%.4f` в терминах спецификаторов языка C.

> Матрицы для проведения вычислений являются квадратными с целью сохранения общего объёма данных для каждого Процесса распределённой системы.

## Описание выходных данных
В результате работы алгоритмов ожидается вектор типа `double` размера первой размерности матрицы (количество её строк), то есть, $24$ при условии выше.

## Описание метрик
Для оценки работы алгоритмы использовались следующие метрики
### Online
* **Время выполнения**. Условия:
    * В начале измерения времени работы алгоритм имеет предварительно загруженные данные Матрицы и Вектора на главном процессе.
    * Завершение измерения времени работы происходит, когда главный процесс получил итоговый вектор $\textemdash$ Результат умножения матрицы на вектор.
    * Время работы измерялось независимо на каждом процессе и впоследствии было агрегировано с использованием функции `max`. 
### Offline
* **Speed Up** (Ускорение)
Вычисляется как частное времени выполнения на одном процессе и на `n` процессах. $$S = \frac{T_{serial}}{T_{parallel}}$$
* **Efficiency** (Эффективность)
Пусть `S` $\textemdash$ ускорение, а `p` $\textemdash$ количество процессов. Тогда эффективность вычисляется как частное ускорения и количества процессов. $$E = \frac{S}{p} = \frac{T_{serial}}{p * T_{parallel}}$$

> Для точности измерений в каждом эксперименте использовалось усреднение 100 экспериментов

## Конфигурация вычислительной машины
* **CPU**: Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz   2.90 GHz. | Cores: 6 | Hyper Threading
* **RAM**: 32,0 ГБ
* **OS**: WSL Ubuntu 22.04.3 LTS

## Визуализация полученных метрик
### Для каждого Алгоритма (Построчно)
<p align="center">
    <img src="https://github.com/YaroslavPr17/MatVec_MPI_Multiplier/assets/77925460/a186cabb-9c47-4d81-bc41-64148c8824db" alt="image" width="100%" height="auto">
</p>

### Сравнение алгоритмов
<p align="center">
    <img src="https://github.com/YaroslavPr17/MatVec_MPI_Multiplier/assets/77925460/1590242f-0a23-4e45-a009-4402630b2dcd" alt="image" width="100%" height="auto">
</p>


## Выводы
### Разделение по строкам
* Чем больше данных, тем заметнее уменьшение **времени** работы
* "Полезными" оказываются процессы до 6-го (на 6 физических ядер процессора). При дальнейшем увеличении (до 12) **время** выполнения увеличивается умеренно (для малых объёмов данных) и драматически возрастает для любого количества данных при увеличении процессов до 24. Причина $\textemdash$ накладные расходы на межпроцессное взаимодействие.
* **Ускорение** максимально при 6 процессах (на 6 физ. ядер).
* Худшее **ускорение**, когда на каждый процесс данных крайне мало.
* **Ускорение** для большей доли наборов данных ведёт себя одинаково.
* **Эффективность** экспоненциально падает в зависимости от количества процессов.
* Наименьшая **эффективность** $\textemdash$ при разделении маленькой задачи на много Worker'ов.

### Разделение по столбцам (Отличия от Алгоритма с разделением по строкам)
* Минимальное **время** исполнения соответствует 6 процессам (на 6 физ. ядер CPU).
* Минимальный набор данных имеет одно из лучших **ускорений** для всех процессов.

### Разделение по блокам (Отличия от Алгоритма с разделением по строкам)
* Лучший результат **времени** на 12 процессах (на 6 физ. ядер) при большом объёме данных. Многопоточность процессора оказывается полезна.

### Сравнение алгоритмов
* Значение **эффективности** и **ускорения** лучше на при всех условиях, однако время выполнения гораздо хуже, чем у других алгоритмов.
* Наименьшее **время** достигается на алгоритме с Блочным разделением.
* При разделении по Столбцам в зависимости от объёма данных **ускорение** и **эффективность** в 2-4 раза лучше при 24 процессах и в 2 раза лучше при 6 активных процессах (на 6 физ. ядер процессора).
